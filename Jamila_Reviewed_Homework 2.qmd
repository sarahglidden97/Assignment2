---
title: "Assignment 2"
subtitle: "Due at 11:59pm on September 30."
format: pdf
editor: visual
---

You may work in pairs or individually for this assignment. Make sure you join a group in Canvas if you are working in pairs. Turn in this assignment as an HTML or PDF file to ELMS. Make sure to include the R Markdown or Quarto file that was used to generate it.

```{r}
#| message: FALSE
#| include: false
# Setup: load packages (install missing ones automatically if needed)
pkgs <- c("tidyverse", "gtrendsR", "censusapi", "readr", "stringr", "ggplot2", "tidyr")
missing <- pkgs[!(pkgs %in% installed.packages()[, "Package"])]
if(length(missing)) install.packages(missing)
library(tidyverse)
library(gtrendsR)
library(censusapi)
library(tidyverse)
library(readr) 
library(stringr) 
library(ggplot2)
library(knitr)
```

In this assignment, you will pull from APIs to get data from various data sources and use your data wrangling skills to use them all together. You should turn in a report in PDF or HTML format that addresses all of the questions in this assignment, and describes the data that you pulled and analyzed. You do not need to include full introduction and conclusion sections like a full report, but you should make sure to answer the questions in paragraph form, and include all relevant tables and graphics.

Whenever possible, use piping and `dplyr`. Avoid hard-coding any numbers within the report as much as possible.

## Pulling from APIs

Our first data source is the Google Trends API. Suppose we are interested in the search trends for `crime` and `loans` in Illinois in the year 2020. We could find this using the following code:

```{r}
res <- gtrends(c("crime", "loans"), 
               geo = "US-IL", 
               time = "2020-01-01 2021-12-31", 
               low_search_volume = TRUE)
names(res)
glimpse(res)
```

Answer the following questions for the keywords "crime" and "loans".

-   Find the mean, median and variance of the search hits for the keywords.

```{r}
stats <- res$interest_over_time %>%
  group_by(keyword) %>%
  summarise(
    mean_hits   = mean(hits, na.rm = TRUE),
    median_hits = median(hits, na.rm = TRUE),
    var_hits    = var(hits, na.rm = TRUE)
  )

stats
```

The mean number of crime hits was 57.7, with a median of 57 and a variance of 63.8. The mean number of loans hits was 66.9 with a median of 66 and a variance of 68.1.

-   Which cities (locations) have the highest search frequency for `loans`? Note that there might be multiple rows for each city if there were hits for both "crime" and "loans" in that city. It might be easier to answer this question if we had the search hits info for both search terms in two separate variables. That is, each row would represent a unique city. - The 10 cities below had the highest search frequency for "loans" during our query time period.

```{r}
cities <- res$interest_by_city %>%
  filter(keyword == "loans") %>%
  select(location, keyword, hits) %>%
  pivot_wider(names_from = keyword, values_from = hits)

# Top cities by "loans"
top_loans <- cities %>%
  arrange(desc(loans))

head (top_loans, 10) # top 10 cities with the highest search frequency for "loans" below

```

Riverdale had the highest search frequency of loans with 100 hits, with Ford Heights and Rosemont have the second highest search frequency with 93 each.

-   Is there a relationship between the search intensities between the two keywords we used?

    -   From the time series plot below, there does not seem to be an apparent association between "crime" and "loans" as they show different trends over time. It indicates that interest in loans surged sharply and peaked around April 2020, during the early months of the COVID-19 pandemic. This was likely due to searches related to financial support, unemployment, and loans. Conversely, crime-related searches surged around June 2020, a time characterized by increased media coverage of crime and protests. Afterwards, searches declined, with moderate activity observed. Loan searches were generally higher than crime searches throughout most of 2020, except in June when crime search spiked.

    ```{r}
    plot(res)
    ```

------------------------------------------------------------------------

**Repeat the above for keywords related to covid. Make sure you use multiple keywords like we did above. Try several different combinations and think carefully about words that might make sense within this context.**

-   Initial search keywords include: covid, mask, pandemic, and vaccine.

```{r}
covid <- gtrends(c("covid", "mask", 
                   "pandemic", "vaccine"), # multiple keywords entered
               geo = "US-IL", 
               time = "2020-01-01 2020-12-31", 
               low_search_volume = TRUE)

plot(covid)
```

-   The two keywords of relevance used are: "covid" and "vaccine".

```{r}
covid_keywords <- gtrends(c("covid", 
                            "vaccine"), # two keyword of relevance picked
                          geo = "US-IL", 
                          time = "2020-01-01 2020-12-31", 
                          low_search_volume = TRUE)

names(covid_keywords)
glimpse(covid_keywords)
```

Answer the following questions for the keywords "covid" and "vaccine".

-   Find the mean, median and variance of the search hits for the keywords.

```{r}
stats <- covid_keywords$interest_over_time %>%
  group_by(keyword) %>%
  mutate(hits = ifelse(hits == "<1", .5, hits),
         hits = as.numeric(hits)) %>%
  summarise(
    mean_hits   = mean(hits, na.rm = TRUE),
    median_hits = median(hits, na.rm = TRUE),
    var_hits    = var(hits, na.rm = TRUE)
  )

stats
```

The mean number of covid hits was 46.0 with a median of 50 and a variance of 683.7. The mean number of vaccine hits was 3.8 with a median of 3 and a variance of 12.0.

-   Which cities (locations) have the highest search frequency for **covid**? Note that there might be multiple rows for each city if there were hits for both "crime" and "loans" in that city. It might be easier to answer this question if we had the search hits info for both search terms in two separate variables. That is, each row would represent a unique city.
    -   The 10 cities below had the highest search frequency for "covid" during our query time period.

```{r}
cities_covid <- covid_keywords$interest_by_city %>%
  filter(keyword == "covid") %>%
  select(location, keyword, hits) %>%
  pivot_wider(names_from = keyword, values_from = hits)

# Top cities by "covid"
top_covid <- cities_covid %>%
  arrange(desc(covid))

head (top_covid, 10)
```

Wheeler had the highest search frequency of covid with 100 hits, with Evergreen Park and Beckemeyer have the second highest search frequency with 81 each.

-   Is there a relationship between the search intensities between the two keywords we used?

    -   Again, from the time series plot below, there does not seem to be an apparent association between "covid" and "vaccine" as they show different trends over time. It looks like "covid" searches surged the most and sharply twice - the outbreak in spring 2020 (around February/March) and again towards the end of 2020 (November/December) which might be attributable to the onset of vaccine approvals and distribution.

    ```{r}
    plot(covid_keywords)
    ```

Now lets add another data set. The `censusapi` package provides a nice R interface for communicating with this API. However, before running queries we need an access key. This (easy) process can be completed here:

<https://api.census.gov/data/key_signup.html>

Once you have an access key, save it as a text file, then read this key in the `cs_key` object. We will use this object in all following API queries. Note that I called my text file `census-key.txt` â€“ yours might be different!

```{r}
cs_key <- read_file("census-key.txt")
```

In the following, we request basic socio-demographic information (population, median age, median household income, income per capita) for cities and villages in the state of Illinois. Documentation for the 5-year ACS API can be found here: <https://www.census.gov/data/developers/data-sets/acs-5year.html>. The information about the variables used here can be found here: <https://api.census.gov/data/2022/acs/acs5/variables.html>.

```{r}
acs_il <- getCensus(name = "acs/acs5",
                    vintage = 2020, 
                    vars = c("NAME", 
                             "B01001_001E", 
                             "B06002_001E", 
                             "B19013_001E", 
                             "B19301_001E"), 
                    region = "place:*", 
                    regionin = "state:17",
                    key = cs_key)
head(acs_il) # to view first few rows

view(acs_il) # review entire data sets
```

Convert values that represent missings to NAs.

```{r}
acs_il[acs_il == -666666666] <- NA

head(acs_il)
```

Now, it might be useful to rename the socio-demographic variables (`B01001_001E` etc.) in our data set and assign more meaningful names.

```{r}
acs_il <-
  acs_il %>%
  rename(pop = B01001_001E, 
         age = B06002_001E, 
         hh_income = B19013_001E, 
         income = B19301_001E)

head(acs_il)
```

It seems like we could try to use this location information listed above to merge this data set with the Google Trends data. However, we first have to clean `NAME` so that it has the same structure as `location` in the search interest by city data. Add a new variable `location` to the ACS data that only includes city names.

-   Adding a new variable "location"

```{r}
acs_il <- acs_il |>  # adding a new variable "location"
  mutate (location = str_extract(NAME, "[^,]+"),
        location = str_remove(location, "village|city|\\stown|CDP"), 
        location = str_trim(location)) 
```

Answer the following questions with the "crime" and "loans" Google trends data and the ACS data.

-   First, check how many cities don't appear in both data sets, i.e. cannot be matched. Then, create a new data set by joining the Google Trends and the ACS data. Keep only cities that appear in both data sets.

    ```         
    8 cities that do not appear in both data sets
    ```

    ```{r}
    asc_crime_loans <- res$interest_by_city |> as_tibble() |> 
      as_tibble() |> 
      mutate(location = str_replace(location, "Saint\\s", "St. "), 
             location = str_replace(location, "Sainte\\s", "Ste. "),
             location = str_remove(location, "Fort ") ) |> 
      # joining crime/loans google trends data with ACS
      left_join(acs_il, relationship = "many-to-many")

    # cities that do not appear in both data sets
    asc_crime_loans |> 
      filter(is.na(NAME)) |> 
      select(location)  # unmatches between both data sets
    count(asc_crime_loans) 
    ```

-   Joining Google Trends and ACS data sets

    ```{r}
    asc_crime_loans <- res$interest_by_city |> as_tibble() |> 
      as_tibble() |> 
      mutate(location = str_replace(location, "Saint\\s", "St. "), 
             location = str_replace(location, "Sainte\\s", "Ste. "),
             location = str_remove(location, "Fort ") ) |> 
      # join with ACS
      left_join(acs_il, relationship = "many-to-many")
    ```

-   Compute the mean of the search popularity for both keywords for cities that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks. What conclusions might you draw from this?

    **Income and Crime:** Cities with higher median household income have a lower mean search popularity (67.4) compared to cities with lower income (72.8) â€“ indicating that as household income increases, interest in crime search popularity decreases, possibly due to safer neighborhoods.

    **Income and Loans:** Cities with higher median income have a slightly higher mean search popularity for loans (54.3) than cities with lower income (52.7) â€“ an indication that higher-income cities have better access to loans or financial opportunities.

    ```{r}
    stats_asc_crime_loans <- 
      asc_crime_loans |> 
      mutate(hh_income_median = 
               ifelse(hh_income > mean(hh_income, na.rm=TRUE),
                      "Higher", "Lower")) |> 
      filter(!is.na(hh_income_median)) |> 
      group_by(hh_income_median, keyword) |> 
      reframe(mean_hits = mean(hits, na.rm=TRUE)) |> 
      pivot_wider(names_from = keyword, values_from = mean_hits)

    stats_asc_crime_loans

    ```

-   Is there a relationship between the median household income and the search popularity of the Google trends terms? Describe the relationship and use a scatterplot with `qplot()`.

    There seems to be linear relationships between median household income and the search popularity of crime and loans. Similar to the observation in the previous question, as median household income increases, crime searches seem to decrease. Conversely, as median household income increases, there appears to be an increase in loan searches.

    -   Median household income and income_loans plot

    ```{r}
    asc_crime_loans |> 
      ggplot(aes(x=hh_income, y=hits, color=keyword)) +
      geom_point() 

    ggplot(asc_crime_loans, aes(x = hh_income, y = hits, color = keyword)) +
      geom_point(alpha = 0.6) +
      labs(
        title = "Income vs Crime & Loans Search Popularity",
        x = "Median household income",
        y = "Search Popularity"
      ) +
      theme_minimal()
    ```

Repeat the above steps using the covid data and the ACS data.

-   First, check how many cities don't appear in both data sets, i.e. cannot be matched. Then, create a new data set by joining the Google Trends and the ACS data. Keep only cities that appear in both data sets.

## Repeating the same steps for COVID keywords

```{r}
# Pull covid keywords
covid_res <- gtrends(
  keyword = c("covid", "vaccine"),
  geo = "US-IL",
  time = "2020-01-01 2020-12-31",
  low_search_volume = TRUE
)

plot(covid_res)
```

8 cities that do not appear in both data sets

```{r}
asc_covid_vaccine <- covid_res$interest_by_city |> as_tibble() |> 
  as_tibble() |> 
  mutate(location = str_replace(location, "Saint\\s", "St. "), 
         location = str_replace(location, "Sainte\\s", "Ste. "),
         location = str_remove(location, "Fort ") ) |> 
  # joining covid/vaccine google trends data with ACS
  left_join(acs_il, relationship = "many-to-many")

# cities that do not appear in both data sets
asc_covid_vaccine |> 
  filter(is.na(NAME)) |> 
  select(location)  # unmatches between both data sets
count(asc_covid_vaccine ) 
```

-   Compute the mean of the search popularity for both keywords for cities that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks. What conclusions might you draw from this?

```{r}
stats_asc_covid_vaccine <- 
  asc_covid_vaccine |> 
  mutate(hh_income_median = 
           ifelse(hh_income > mean(hh_income, na.rm=TRUE),
                  "Higher", "Lower")) |> 
  filter(!is.na(hh_income_median)) |> 
  group_by(hh_income_median, keyword) |> 
  reframe(mean_hits = mean(hits, na.rm=TRUE)) |> 
  pivot_wider(names_from = keyword, values_from = mean_hits)

stats_asc_covid_vaccine
```

-   Median household income and covid_vaccine plot

```{r}
ggplot(asc_covid_vaccine, aes(x = hh_income, y = hits, color = keyword)) +
  geom_point(alpha = 0.6) +
  labs(
    title = "Income vs Covid & Vaccine Search Popularity",
    x = "Median household income",
    y = "Search Popularity"
  ) +
  theme_minimal()
```
